---
title: "Shameless Baseball Love"
output: html_document
---

I play fantasy baseball.  In some ways, I'm embarrassed to admit it.  I recall being teased for this on more than one occassion when I first started playing these games over 10 years ago.  However, I think I'm in good company today.  The Fantasy Sports Trade Association (FSTA) has estimated the number of individuals playing fantasy sports in the US and Canada at [over 41 million][ref1].  While I'm not confident that the FSTA is an unbiased party, I think that the figure is in the general ballpark of being correct.  

Regardless, I'm through defending myself.  I need to figure out how I'm going to draft my players!  There are a variety of ways to obtain predictions for how individual players will do for the upcoming season.  The website [Fangraphs][ref2] includes a handy feature which allows you to download csv files of their projections.  They include projections from the ZIPS 


```{r, warning=FALSE, echo=FALSE}
menus<-readLines('../Data/menustat-546cf6b433804.csv')
menus<-menus[-1]
menus<-gsub('\t-', '', menus)
menus<-gsub('\t', '', menus)
menus<-read.csv(textConnection(menus)) #this takes a minute...
submenus<-menus[,3:51] #leave 'Restuarant', 'Food Category', and 'Menu Item ID' untouched.
submenus[]<-lapply(submenus, as.character)
menus[,3:51]<-submenus

submenus<-menus[,c(7:15, 19:51)]
submenus[]<-lapply(submenus, as.numeric)
menus[,c(7:15, 19:51)]<-submenus

library(reshape2)
library(stringr)
library(plyr)
df <- melt(menus, id.vars = c('Restaurant.', 'Food.Category.', 'Item_Name.', 
                           'Menu_Item_ID'))
df$year <- df$variable
levels(df$year) <- str_match(levels(df$variable), "[0-9]{4}")
levels(df$variable) <- gsub('\\.{1,2}', '', levels(df$variable))#remove dots
levels(df$variable) <- gsub('[0-9]', '', levels(df$variable))#remove year
levels(df$variable) <- gsub('\\s+$', '', levels(df$variable))#remove trailing space
df<-dcast(df, Restaurant. + Food.Category. + Item_Name. + Menu_Item_ID + year ~ 
           variable , value.var = 'value')
df<-arrange(df, Restaurant., Item_Name.)
df$Carbohydratesg[131161] <- NA
df[75620, 16] <- 300
df[75620, 21] <- 3
df[75815, 16] <- 250
df[75815, 21] <- 3
df[122305,12] <- NA
df[122305,11] <- NA
df$Calories <- as.numeric(df$Calories)
df$Proteing <- as.numeric(df$Proteing)
df$TotalFatg <- as.numeric(df$TotalFatg)
df$Carbohydratesg <- as.numeric(df$Carbohydratesg)

library(lme4)
names(df)[1] <- 'Restaurant'
```

```{r, warning=FALSE}
m.1 <- lmer(Calories ~ Proteing + Carbohydratesg + TotalFatg + 
       (1+Proteing+Carbohydratesg+TotalFatg|Restaurant), data=df)
summary(m.1)
```

Note that the estimates in the model are very close to what we would expect, based on the lawful relationship between each macronutrient and calories:

- **Fats:** 9 kcal/gram
- **Protiens:** 4 kcal/gram
- **Carbohydrates:** 4 kcal/gram

However, it isn't perfect.  In fact, the *way* in which it isn't perfect made me a little suspicious.  Specifically, the estimates all move in the same direction one would expect if there was some kind of social desireability bias at play (i.e. higher than expected protein, lower than expected carbs & fats).  To investigate this more closely, I created an index of the random effects which is a measure of how much each restaurant's nutrition information is biased in socially desireable ways.  I refer to the index as 'reporting tendency'.  Negative numbers represent nutrition information which is more socially desireable

```{r}
rf <- ranef(m.1)
df.rf <- rf$Restaurant
head(df.rf)
df.rf$Proteing <- scale(df.rf$Proteing)
df.rf$Proteing <- df.rf$Proteing*-1
df.rf$Carbohydratesg <- scale(df.rf$Carbohydratesg)
df.rf$TotalFatg <- scale(df.rf$TotalFatg)

library(ggplot2)
df.rf$reporting.tendency <- df.rf$Proteing + df.rf$Carbohydratesg + 
  df.rf$TotalFatg
ggplot(df.rf, aes(x=reporting.tendency)) + 
  geom_histogram(binwidth=.2, fill='#144256') + 
  theme_bw() + ylab('Count') + xlab('Reporting Tendency')
```

Note that we've got a couple of clear outliers.  It could be these restaurants which are driving this pattern.  Perhaps this is another instance of the data being mis-entered.  Let's dive in and see who these two are.

```{r}
df.rf[which(df.rf$reporting.tendency < -10), ]
```

Remember that these random effects estimates have all been standardized, so when you see that the estimate for fat is -8.6 as it is for Round Table Pizza, that means that the random effect of total fat for Round Table is 8.6 standard deviations below the mean!  Clearly, we should examine the raw data for these two companies.  Since they both have quite a large number of items (789 for Godfather, 1266 for Round Table), I'm going to place them into their own dataframe and then look at a scatter of each macronutrient against total calories.

```{r}
df.pizza <- rbind(df[which(df$Restaurant == "Godfather's Pizza"),],
                      df[which(df$Restaurant == "Round Table Pizza"),])
ggplot(df.pizza, aes(x=Carbohydratesg, y=Calories)) +
  geom_point(color='#88301B') + facet_wrap(~Restaurant) + 
  theme_bw()
ggplot(df.pizza, aes(x=TotalFatg, y=Calories)) +
  geom_point(color='#88301B') + facet_wrap(~Restaurant) +
  theme_bw()
ggplot(df.pizza, aes(x=Proteing, y=Calories)) +
  geom_point(color='#88301B') + facet_wrap(~Restaurant) +
  theme_bw()
```

This doesn't look like anything too fishy.  I'm guessing that the huge effect of carbs in Godfather's is being driven by the outlier way out ~175 carbs and 125 calories.  Ditto for Round Table being driven by the outlier out near 150 grams of fat.  Interestingly, the plot for carbohydrates seems to have two distinct groups in both chains, but it is esspecially pronounced for Round Table.  Note all the data points clustered together in a line that is below the larger cluster.  It looks like if we define a line that runs through the origin and the point (x=50, y=250), we can just grab the values which are below that for a sense of what these items are.  Let's give that a shot.

```{r}
df.pizza$line <- 5*df.pizza$Carbohydratesg
ggplot(df.pizza, aes(x=Carbohydratesg, y=Calories)) +
  geom_point(color='#88301B') + facet_wrap(~Restaurant) + 
  geom_line(aes(x=Carbohydratesg, y=line), color='#144256')+
  theme_bw()
```

That looks okay.  Let's get everything smaller than the values in that line.

```{r}
df.pizza[sample(which(df.pizza$Calories < df.pizza$line), 20),c(1, 3, 11, 12, 18, 21)]
```

Ah.  Basically, this is soda, which is typically made up of nothing but carbohydrates.

Okay, let's remove the two crazy outliers and see about refitting the model.

```{r}
library(dplyr)
df %>%
  filter(TotalFatg>125) %>%
  filter(Restaurant == "Round Table Pizza")
df %>%
  filter(Carbohydratesg>150) %>%
  filter(Restaurant == "Godfather's Pizza")
```

Okay, items 72354 and 43760.  We can remove those without too much difficulty.  Let's just double check that we wont do too much damage by removing all carb and fat entires with those values.

```{r}
df[which(df$Menu_Item_ID == 43760),]
df[which(df$Menu_Item_ID == 72354),]
```

Checks out okay - the other years are all NA anyway.  Let's remove and refit the model



[ref1]:  <http://www.fsta.org/?page=Demographics>
[ref2]:  <http://www.fangraphs.com>