---
title: ""
output: html_document
---

Last time, I examined the relationship between macronutrients and total calories in the data obtained from [menustat.org][ref1].  If you'll recall, I made an interesting observation.  Here's the model I had fit:


```{r, warning=FALSE, echo=FALSE}
menus<-readLines('../Data/menustat-546cf6b433804.csv')
menus<-menus[-1]
menus<-gsub('\t-', '', menus)
menus<-gsub('\t', '', menus)
menus<-read.csv(textConnection(menus)) #this takes a minute...
submenus<-menus[,3:51] #leave 'Restuarant', 'Food Category', and 'Menu Item ID' untouched.
submenus[]<-lapply(submenus, as.character)
menus[,3:51]<-submenus

submenus<-menus[,c(7:15, 19:51)]
submenus[]<-lapply(submenus, as.numeric)
menus[,c(7:15, 19:51)]<-submenus

library(reshape2)
library(stringr)
library(plyr)
df <- melt(menus, id.vars = c('Restaurant.', 'Food.Category.', 'Item_Name.', 
                           'Menu_Item_ID'))
df$year <- df$variable
levels(df$year) <- str_match(levels(df$variable), "[0-9]{4}")
levels(df$variable) <- gsub('\\.{1,2}', '', levels(df$variable))#remove dots
levels(df$variable) <- gsub('[0-9]', '', levels(df$variable))#remove year
levels(df$variable) <- gsub('\\s+$', '', levels(df$variable))#remove trailing space
df<-dcast(df, Restaurant. + Food.Category. + Item_Name. + Menu_Item_ID + year ~ 
           variable , value.var = 'value')
df<-arrange(df, Restaurant., Item_Name.)
df$Carbohydratesg[131161] <- NA
df[75620, 16] <- 300
df[75620, 21] <- 3
df[75815, 16] <- 250
df[75815, 21] <- 3
df[122305,12] <- NA
df[122305,11] <- NA
df$Calories <- as.numeric(df$Calories)
df$Proteing <- as.numeric(df$Proteing)
df$TotalFatg <- as.numeric(df$TotalFatg)
df$Carbohydratesg <- as.numeric(df$Carbohydratesg)

library(lme4)
names(df)[1] <- 'Restaurant'
```

```{r, warning=FALSE}
m.1 <- lmer(Calories ~ Proteing + Carbohydratesg + TotalFatg + 
       (1+Proteing+Carbohydratesg+TotalFatg|Restaurant), data=df)
summary(m.1)
```

Note that the estimates in the model are very close to what we would expect, based on the lawful relationship between each macronutrient and calories:

- **Fats:** 9 kcal/gram
- **Protiens:** 4 kcal/gram
- **Carbohydrates:** 4 kcal/gram

However, it isn't perfect.  In fact, the *way* in which it isn't perfect made me a little suspicious.  Specifically, the estimates all move in the same direction one would expect if there was some kind of social desireability bias at play (i.e. higher than expected protein, lower than expected carbs & fats).  To investigate this more closely, I created an index of the random effects which is a measure of how much each restaurant's nutrition information is biased in socially desireable ways.  I refer to the index as 'reporting tendency'.  Negative numbers represent nutrition information which is more socially desireable

*Question of interest:  What happens if I standardize the random effects versus standardize the predictors in the model?*

```{r}
rf <- ranef(m.1)
df.rf <- rf$Restaurant
head(df.rf)
df.rf$Proteing <- scale(df.rf$Proteing)
df.rf$Proteing <- df.rf$Proteing*-1
df.rf$Carbohydratesg <- scale(df.rf$Carbohydratesg)
df.rf$TotalFatg <- scale(df.rf$TotalFatg)

library(ggplot2)
df.rf$reporting.tendency <- df.rf$Proteing + df.rf$Carbohydratesg + 
  df.rf$TotalFatg
ggplot(df.rf, aes(x=reporting.tendency)) + 
  geom_histogram(binwidth=.2, fill='#144256') + 
  theme_bw() + ylab('Count') + xlab('Reporting Tendency')
```

Note that we've got a couple of clear outliers.  It could be these restaurants which are driving this pattern.  Perhaps this is another instance of the data being mis-entered.  Let's dive in and see who these two are.

```{r}
df.rf[which(df.rf$reporting.tendency < -10), ]
```

Remember that these random effects estimates have all been standardized, so when you see that the estimate for fat is -8.6 as it is for Round Table Pizza, that means that the random effect of total fat for Round Table is 8.6 standard deviations below the mean!  Clearly, we should examine the raw data for these two companies.  Since they both have quite a large number of items (789 for Godfather, 1266 for Round Table), I'm going to place them into their own dataframe and then look at a scatter of each macronutrient against total calories.

```{r}
df.pizza <- rbind(df[which(df$Restaurant == "Godfather's Pizza"),],
                      df[which(df$Restaurant == "Round Table Pizza"),])
ggplot(df.pizza, aes(x=Carbohydratesg, y=Calories)) +
  geom_point(color='#88301B') + facet_wrap(~Restaurant) + 
  theme_bw()
ggplot(df.pizza, aes(x=TotalFatg, y=Calories)) +
  geom_point(color='#88301B') + facet_wrap(~Restaurant) +
  theme_bw()
ggplot(df.pizza, aes(x=Proteing, y=Calories)) +
  geom_point(color='#88301B') + facet_wrap(~Restaurant) +
  theme_bw()
```

This doesn't look like anything too fishy.  Just a couple of huge outliers that are pretty clearly mis-entered data.  The one exception is the plot for carbs.  Round Table seems to have two distinct groups.  It looks like if we define a line that runs through the origin and the point (x=50, y=250), we can just grab the values which are below that for a sense of what these items are.  Let's give that a shot.

```{r}
df.pizza$line <- 5*df.pizza$Carbohydratesg
ggplot(df.pizza, aes(x=Carbohydratesg, y=Calories)) +
  geom_point(color='#88301B') + facet_wrap(~Restaurant) + 
  geom_line(aes(x=Carbohydratesg, y=line), color='#144256')+
  theme_bw()
```

That looks okay.  Let's get everything smaller than the values in that line.

```{r}
df.pizza[which(df.pizza$Calories < df.pizza$line),c(1, 3, 11, 12, 18, 21)]
```

Ah.  Basically, this is soda, which is typically made up of nothing but carbohydrates.  



[ref1]:  <http://api.ning.com/files/drL7ji10lw0df0UGzfzR3Wgna8ZmVV2JSf-ebXK3ggx1hTZlYsoH5*nmXIW9-QjqmRicEjoeROQZ4I*FS3FQKPxRpAZuKxwx/100_0218.JPG?width=737&height=552>