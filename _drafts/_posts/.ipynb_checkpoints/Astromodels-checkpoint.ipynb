{
 "metadata": {
  "name": "",
  "signature": "sha256:7ac8b2dfe4581949d078f2d817480cd99b360942b8e1df5c5af20c8198536cfd"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In the last post, I described my efforts at grabbing some data from a web site. Specifically, I scraped daily horoscopes from NYpost for a period of about a year and a half. While I have an admittedly poor understanding of astrology, I do know that each astrological sign is supposed confer some unique dispositional qualities to anyone born under that sign. If that's true, then we would expect that the astrological readings would reflect the uniqueness of each sign. To be more explicit, the language found in a horoscope for each sign should carry some information about which sign it is most likely to belong to.\n",
      "\n",
      "This is something that we can evaluate using the data I collected previously. In order to do so, we're going to use a couple of supervised learning methods.\n",
      "\n",
      "Friedman, Tibshirani & Hastie, in their widely used text *The Elements of Statistical Learning* describe machine learning algorithms with an analogy that I think works pretty well. The compare a supervised learning algorithm to a student in a classroom. For the student to learn something, the teacher presents him or her with some example problems along with the answers. The student learns the relationship between the problems and answers, and then applies what it has learned to some new problems, attempting to guess the correct answer.\n",
      "\n",
      "In this analogy, the problems are the data and the answers are the labels or categories that each observation belongs to. For our dataset, the data are the individual horoscopes readings and the labels are the horoscope types that each corresponds to.\n",
      "\n",
      "First, we'll read in the data and look at the first few rows."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "df = pd.read_csv('./../data/astrosign.csv', sep='|')\n",
      "df = df.drop('Unnamed: 0', 1)\n",
      "df=df.dropna()\n",
      "df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>horoscope</th>\n",
        "      <th>pub_date</th>\n",
        "      <th>zodiac</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> What is your fondest dream? What is it you wou...</td>\n",
        "      <td> 12-01-2013</td>\n",
        "      <td> aquarius</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> Just because something is new-fangled or fashi...</td>\n",
        "      <td> 12-02-2013</td>\n",
        "      <td> aquarius</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> Some people react well to criticism and some p...</td>\n",
        "      <td> 12-03-2013</td>\n",
        "      <td> aquarius</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> You are advised not to make any hasty decision...</td>\n",
        "      <td> 12-04-2013</td>\n",
        "      <td> aquarius</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> Friendships and social activities are under ex...</td>\n",
        "      <td> 12-05-2013</td>\n",
        "      <td> aquarius</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "                                           horoscope    pub_date    zodiac\n",
        "0  What is your fondest dream? What is it you wou...  12-01-2013  aquarius\n",
        "1  Just because something is new-fangled or fashi...  12-02-2013  aquarius\n",
        "2  Some people react well to criticism and some p...  12-03-2013  aquarius\n",
        "3  You are advised not to make any hasty decision...  12-04-2013  aquarius\n",
        "4  Friendships and social activities are under ex...  12-05-2013  aquarius"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The python module scikit-learn makes implementing a classifier fairly straightforward. First, we have to quantify all this text. That is, we have to create a numeric model of our language (i.e. a *language model*). One of the most straightforward ways of doing this is by creating a document-term matrix. This matrix features one row for each individual document and one column for each word that appears in the accumulated corpus of all the documents.\n",
      "\n",
      "The values of the cells of this matrix can take on a number of forms. We'll use a simple count of the number of times a given word appears in a given document.\n",
      "\n",
      "In scikit learn, all this is done in two short lines."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "cv = CountVectorizer()\n",
      "wordcounts = cv.fit_transform(df['horoscope'])\n",
      "wordcounts"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "<6271x5505 sparse matrix of type '<type 'numpy.int64'>'\n",
        "\twith 224419 stored elements in Compressed Sparse Row format>"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So that's four lines, but one is just importing the module and the last line is just to display what we've done.\n",
      "\n",
      "We can see that this matrix  has a total of 224,419 non-zero elements. That may seem like a lot until you consider that our matrix has 6271 rows (one for each horoscope) and 5505 columns (one for each word type), making for a total of about 34.5 million cells. This tells us that there are a whole lot of zeros in this matrix. This is typical for a language model like this.\n",
      "\n",
      "So this forms our basic language model. We can use this simplistic representation to see if we can train a learner to distinguish between horoscopes from different astrological signs. For our first classifier, let's see how a support vector machine does. We're going to train the classifier on 70% of our data, holding out the remaining 30% to test it's knowledge of the relationship between the text and the zodiac labels in the same way you would wait to show a student some examples until the final exam."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn import svm\n",
      "\n",
      "scope_train, scope_test, sign_train, sign_true = \\\n",
      "    train_test_split(wordcounts, \n",
      "                     df['zodiac'], \n",
      "                     test_size=.3, \n",
      "                     random_state=43)\n",
      "\n",
      "clf = svm.LinearSVC()\n",
      "clf.fit(scope_train, sign_train)\n",
      "\n",
      "predicted = clf.predict(scope_test)\n",
      "scores = metrics.classification_report(sign_true, predicted)\n",
      "print scores"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "             precision    recall  f1-score   support\n",
        "\n",
        "   aquarius       0.07      0.08      0.08       154\n",
        "      aries       0.08      0.07      0.07       146\n",
        "     cancer       0.01      0.01      0.01       167\n",
        "  capricorn       0.04      0.05      0.05       151\n",
        "     gemini       0.00      0.00      0.00       133\n",
        "        leo       0.21      0.18      0.19       167\n",
        "      libra       0.15      0.12      0.13       171\n",
        "     pisces       0.11      0.13      0.12       150\n",
        "sagittarius       0.13      0.13      0.13       156\n",
        "    scorpio       0.14      0.11      0.13       169\n",
        "     taurus       0.00      0.00      0.00       170\n",
        "      virgo       0.10      0.09      0.10       148\n",
        "\n",
        "avg / total       0.09      0.08      0.09      1882\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now that we've fit a model, we can give this model some new data and tell it to give us its predictions. In other words, we're going to give the model some new horoscopes and see how well it can place them as Aquarius or Pisces or what have you."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import metrics\n",
      "\n",
      "\n",
      "\n",
      "predicted = clf.predict(scope_test)\n",
      "scores = metrics.classification_report(sign_true, predicted)\n",
      "print scores"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "             precision    recall  f1-score   support\n",
        "\n",
        "   aquarius       0.09      0.07      0.08       176\n",
        "      aries       0.12      0.14      0.13       138\n",
        "     cancer       0.00      0.00      0.00       173\n",
        "  capricorn       0.07      0.08      0.08       148\n",
        "     gemini       0.00      0.00      0.00       155\n",
        "        leo       0.13      0.10      0.12       163\n",
        "      libra       0.17      0.15      0.16       155\n",
        "     pisces       0.13      0.13      0.13       147\n",
        "sagittarius       0.13      0.13      0.13       145\n",
        "    scorpio       0.18      0.17      0.17       168\n",
        "     taurus       0.00      0.00      0.00       145\n",
        "      virgo       0.10      0.08      0.09       169\n",
        "\n",
        "avg / total       0.09      0.09      0.09      1882\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Okay, so this is relatively straightforward. We see the 12 signs down the left-hand side. The next column is the precision for each sign. Precision is a score that tells us how well the classifier identifies a category when it tries to do so. So, we see a score of 9% for aquarius. This means that, if the classifier labeled 100 horoscopes as 'aquarius', it was correct on 9 of those guesses.\n",
      "\n",
      "Recall tells us how well the classifier does at identifying horoscopes from a given astrological sign. So, if there are 100 horoscopes labeled as 'aries', the classifier correctly guessed 14 of those.\n",
      "\n",
      "The f1 score is the average of precision and recall, while support"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "What about using the same information to predict which month of the year the horoscope was written? It seems downright probable that the writer of the horoscope could be influenced by the weather, and that her horoscopes would reflect that influence. Conveniently, there are also 12 months in the year, so the models are, in some sense, directly comparable.\n",
      "\n",
      "First, let's pull the month from that date column"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "date = df['pub_date'].map(lambda x: str(x)[0:2])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 41,
       "text": [
        "'12'"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, we can repeat the above procedure with this new set of labels."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "scope_train, scope_test, month_train, month_true = \\\n",
      "    train_test_split(wordcounts, \n",
      "                     date, \n",
      "                     test_size=.3, \n",
      "                     random_state=42)\n",
      "\n",
      "clf = svm.LinearSVC()\n",
      "clf.fit(scope_train, month_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 48,
       "text": [
        "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
        "     intercept_scaling=1, loss='l2', multi_class='ovr', penalty='l2',\n",
        "     random_state=None, tol=0.0001, verbose=0)"
       ]
      }
     ],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "predicted = clf.predict(scope_test)\n",
      "scores = metrics.classification_report(month_true, predicted)\n",
      "print scores"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "             precision    recall  f1-score   support\n",
        "\n",
        "         01       0.32      0.33      0.33       203\n",
        "         02       0.35      0.33      0.34       210\n",
        "         03       0.31      0.37      0.34       207\n",
        "         04       0.27      0.33      0.30       190\n",
        "         05       0.28      0.26      0.27       186\n",
        "         06       0.32      0.32      0.32       117\n",
        "         07       0.31      0.21      0.25       126\n",
        "         08       0.24      0.26      0.25       108\n",
        "         09       0.37      0.28      0.32       113\n",
        "         10       0.36      0.31      0.34       102\n",
        "         11       0.31      0.28      0.30       102\n",
        "         12       0.31      0.31      0.31       218\n",
        "\n",
        "avg / total       0.31      0.31      0.31      1882\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 49
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "HA! We know more about the month of the year than we do about the astrological sign being discussed. Man my job is cool."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}